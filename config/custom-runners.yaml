# Configuration for custom GitHub Actions runners
# This file configures additional runner scale sets with different images

# Runner Scale Set Configuration
runnerSet:
  # Name of the runner set
  name: "custom-runners"
  
  # Repository or organization to deploy runners for
  # Uncomment and set one of these:
  # repository: "your-org/your-repo"
  organization: "your-org"
  # enterprise: "your-enterprise"
  
  # Runner labels for job targeting
  labels:
    - "self-hosted"
    - "linux"
    - "x64"
    - "custom"
    - "gpu"
  
  # Number of replicas (runners)
  replicas: 1
  
  # Minimum number of replicas
  minReplicas: 0
  
  # Maximum number of replicas
  maxReplicas: 5
  
  # Custom runner image with additional tools
  image: "ghcr.io/actions/actions-runner:latest"
  
  # Docker configuration
  docker:
    enabled: true
    dockerdWithinRunnerContainer: false
    mtu: 1500
    mirror: ""
  
  # Runner resources (higher for custom workloads)
  resources:
    requests:
      cpu: 2000m
      memory: 4Gi
    limits:
      cpu: 8000m
      memory: 16Gi
  
  # Runner environment variables
  env:
    - name: RUNNER_LABELS
      value: "custom,linux,x64,gpu"
    - name: RUNNER_GROUP
      value: "custom-runners"
    - name: CUDA_VISIBLE_DEVICES
      value: "0"
    - name: NVIDIA_VISIBLE_DEVICES
      value: "all"
  
  # Runner volume mounts for custom tools
  volumeMounts:
    - name: custom-tools
      mountPath: /opt/custom-tools
      readOnly: true
    - name: gpu-drivers
      mountPath: /usr/local/cuda
      readOnly: true
  
  # Runner volumes
  volumes:
    - name: custom-tools
      hostPath:
        path: /opt/custom-tools
        type: Directory
    - name: gpu-drivers
      hostPath:
        path: /usr/local/cuda
        type: Directory
  
  # Working directory
  workDir: "/runner/_work"
  
  # Node selector for GPU nodes
  nodeSelector:
    accelerator: nvidia
    node.kubernetes.io/instance-type: "Standard_NC6s_v3"
  
  # Tolerations for GPU nodes
  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule
  
  # Auto-scaling configuration
  autoscaling:
    enabled: true
    # Horizontal Pod Autoscaler configuration
    hpa:
      enabled: true
      minReplicas: 0
      maxReplicas: 5
      targetCPUUtilizationPercentage: 70
      targetMemoryUtilizationPercentage: 70
      scaleDownDelaySecondsAfterAdd: 600
      scaleDownDelaySecondsAfterDelete: 600
      scaleDownDelaySecondsAfterFailure: 300
      scaleDownUnneededTimeSeconds: 900
      scaleDownUtilizationThreshold: 0.3
    
    # Behavior configuration
    behavior:
      scaleDown:
        stabilizationWindowSeconds: 600
        policies:
          - type: Percent
            value: 25
            periodSeconds: 120
      scaleUp:
        stabilizationWindowSeconds: 0
        policies:
          - type: Percent
            value: 100
            periodSeconds: 30
          - type: Pods
            value: 2
            periodSeconds: 30
        selectPolicy: Max

# AKS-specific configurations
aks:
  # Use Azure CNI
  useAzureCNI: true
  
  # Azure storage class
  storageClass: "managed-premium"
  
  # Azure node pool configuration for GPU nodes
  nodePool:
    # Node pool name for runners
    name: "gpu-runner-pool"
    
    # Node pool labels
    labels:
      node.kubernetes.io/instance-type: "Standard_NC6s_v3"
      accelerator: nvidia
    
    # Node pool taints
    taints:
      - key: nvidia.com/gpu
        value: present
        effect: NoSchedule
    
    # Node pool annotations
    annotations: {}

# Monitoring and logging
monitoring:
  enabled: true
  
  # Pod disruption budget
  pdb:
    enabled: true
    minAvailable: 0

# Pod disruption budget
pdb:
  enabled: true
  minAvailable: 0 